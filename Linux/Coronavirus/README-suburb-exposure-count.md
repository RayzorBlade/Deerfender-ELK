# Suburb Exposure Count
<br />

## Summary

During a Melbourne COVID-19 lockdown, I found myself going to the official government coronavirus exposure site Web site regularly to check if there were any new COVID exposure sites in Melbourne suburbs near me.  

While it was a nice Website, it took time and effort to scroll through each page, just to know whether there have been any additional suburbs or exposure sites identified near my local area.    

So I reverse engineered the Web site, and wrote the suburb-exposure-count script, to run in GitBash whenever I wanted a quick update.  

A colleague asked how I went about discovering how to extract this information and construct the script. As such, I've included a write-up below.
<br />
<br />

## Script Explained

To create this script, I started by visiting https://www.coronavirus.vic.gov.au/exposure-sites through Chrome, and used the developer tools 'Inspect Element' feature to see how I could extract the underlying text.  

I found it interesting when I simply curl'ed the above URL, the suburb information wasn't there, but it was visible when viewed through 'Inspect Element'. Turns out the information of interest was loaded dynamically by JavaScript after the main HTML page loads.  

So, while on the main page, I went to the 'Network' tab within 'Inspect Element', clicked Ctrl+R to reload the page, and did a Crtl+F to search for the word "Yarraville" as this was one of the suburbs listed on the page.  

Chrome highlighted the URL that gets called to extract the suburb and related data.  

From the list of requests, I selected the highlighted resource (sdp-ckan?resource_id=\<blah\>), right mouse-clicked and selected 'Copy -> Copy as cCurl (bash). I noted later that the resulting curl also contained header and cookie information specific to my Chrome browsing session, so I stripped this back to just the main URL. I was curious as to whether the curl command still needed the authentication header directives or other supplementary details included in the original curl command generated by Chrome, but turns out it didn't.  

Next, I pasted the curl command into GitBash and it extracted all the data I was after (and I added the -s switch to remove the annoying preamble output).  

Reading the first part of the returned info showed the api URL (https://discover.data.vic.gov.au/api) with some help on how to use it. It mentioned you should send appropriate authentication details to use it, so I suspect the authentication headers in the original Chrome provided URL might be able to be used to query this API in more detail, but didn't look into this at all, as I had all the info I needed from the first curl query, and was just after a quick and dirty outcome.  

A snippet of the returned data looked like below. I was interested in the suburb details. I could have pulled out a lot of other info too, but that wasn't the point of this exercise.  

```
"_id":1,"Suburb":"Abbotsford","Site_title":"Dukes Gym Abbotsford","Site_streetaddress":"571-573 Victoria Street","Site_state":"VIC","Site_postcode":"3067","Exposure_date_dtm":"2021-05-24","Exposure_date":"24/05/2021","Exposure_time":"6:15pm - 8:15pm","Notes":"Case attended venue","Added_date_dtm":"2021-05-26","Added_date":"26/05/2021","Added_time":"11:20 am","Advice_title":"Tier 1 - Get tested immediately and quarantine for 14 days from exposure","Advice_instruction":"Anyone who has visited this location during these times must get tested immediately and quarantine for 14 days from the exposure.","Exposure_time_start_24":"18:15:00","Exposure_time_end_24":"20:15:00"},{"_id":2,"Suburb":"Axedale","Site_title":"Axedale Tavern","Site_streetaddress":"105 High Street",
```

Now just needed to pipe this to text processing commands to extract details in the format I wanted. I'll break that down too...  


1) `| grep -oE '"Suburb":"[^"]+"'` - Uses regular expression (regex) to find the pattern "Suburb" (including quotes), followed by a colon, followed by a double-quote, then one or more of anything that isn't a double-quote (aka the suburb name), then the closing double-quote. So, from the above snippet, we end up with the following:  

  ```
  | grep -oE '"Suburb":"[^"]+"'
  "Suburb":"Abbotsford"
  "Suburb":"Axedale"
  ```
  
2) Next, used awk, sort and uniq to count the number of times each suburb appears (deriving the number of exposure sites per suburb). So the above would look like this:  
  ```
  | awk -F':' '{print $2}' | sort | uniq -c
  1 "Abbotsford"
  1 "Axedale"  
  ```
  
3) Finally, used awk to flip the suburb name and count fields so that the suburb appears on the left, and inject a colon so that the next command (column) can use it as a delimiter and format it nicely as a table.  

  ```
  | awk -F'"' '{print $2 ":" $1}' | column --table -s ":"
  Abbotsford               1
  Axedale                  1  
  ```

Hope that wasn't too verbose. I guess if you're still reading this, then you made it to the end without falling asleep, so happy days :)  

Cheers,  
Ray 